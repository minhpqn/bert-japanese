{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the pretrained Japanese BERT model\n",
    "\n",
    "Finetune the pretrained model to solve multi-class classification problems.  \n",
    "This notebook requires the following objects:\n",
    "- trained sentencepiece model (model and vocab files)\n",
    "- pretraiend Japanese BERT model\n",
    "\n",
    "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
    "We make test:dev:train = 2:2:6 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "- Full training data\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.98      0.94      0.96       178\n",
    "      it-life-hack       0.96      0.97      0.96       172\n",
    "     kaden-channel       0.99      0.98      0.99       176\n",
    "    livedoor-homme       0.98      0.88      0.93        95\n",
    "       movie-enter       0.96      0.99      0.98       158\n",
    "            peachy       0.94      0.98      0.96       174\n",
    "              smax       0.98      0.99      0.99       167\n",
    "      sports-watch       0.98      1.00      0.99       190\n",
    "        topic-news       0.99      0.98      0.98       163\n",
    "\n",
    "         micro avg       0.97      0.97      0.97      1473\n",
    "         macro avg       0.97      0.97      0.97      1473\n",
    "      weighted avg       0.97      0.97      0.97      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.89      0.86      0.88       178\n",
    "      it-life-hack       0.91      0.90      0.91       172\n",
    "     kaden-channel       0.90      0.94      0.92       176\n",
    "    livedoor-homme       0.79      0.74      0.76        95\n",
    "       movie-enter       0.93      0.96      0.95       158\n",
    "            peachy       0.87      0.92      0.89       174\n",
    "              smax       0.99      1.00      1.00       167\n",
    "      sports-watch       0.93      0.98      0.96       190\n",
    "        topic-news       0.96      0.86      0.91       163\n",
    "\n",
    "         micro avg       0.92      0.92      0.92      1473\n",
    "         macro avg       0.91      0.91      0.91      1473\n",
    "      weighted avg       0.92      0.92      0.91      1473\n",
    "    ```\n",
    "\n",
    "- Small training data (1/5 of full training data)\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.97      0.87      0.92       178\n",
    "      it-life-hack       0.86      0.86      0.86       172\n",
    "     kaden-channel       0.95      0.94      0.95       176\n",
    "    livedoor-homme       0.82      0.82      0.82        95\n",
    "       movie-enter       0.97      0.99      0.98       158\n",
    "            peachy       0.89      0.95      0.92       174\n",
    "              smax       0.94      0.96      0.95       167\n",
    "      sports-watch       0.97      0.97      0.97       190\n",
    "        topic-news       0.94      0.94      0.94       163\n",
    "\n",
    "         micro avg       0.93      0.93      0.93      1473\n",
    "         macro avg       0.92      0.92      0.92      1473\n",
    "      weighted avg       0.93      0.93      0.93      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.82      0.71      0.76       178\n",
    "      it-life-hack       0.86      0.88      0.87       172\n",
    "     kaden-channel       0.91      0.87      0.89       176\n",
    "    livedoor-homme       0.67      0.63      0.65        95\n",
    "       movie-enter       0.87      0.95      0.91       158\n",
    "            peachy       0.70      0.78      0.73       174\n",
    "              smax       1.00      1.00      1.00       167\n",
    "      sports-watch       0.87      0.95      0.91       190\n",
    "        topic-news       0.92      0.82      0.87       163\n",
    "\n",
    "         micro avg       0.85      0.85      0.85      1473\n",
    "         macro avg       0.85      0.84      0.84      1473\n",
    "      weighted avg       0.86      0.85      0.85      1473\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/minhpqn/workspace/bert-japanese/notebook/../config.ini']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "CURDIR = os.getcwd()\n",
    "CONFIGPATH = os.path.join(CURDIR, os.pardir, 'config.ini')\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing\n",
    "\n",
    "You need execute the following cells just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 1.87 s, total: 3.5 s\n",
      "Wall time: 6.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "urlretrieve(FILEURL, FILEPATH)\n",
    "\n",
    "mode = \"r:gz\"\n",
    "tar = tarfile.open(FILEPATH, mode) \n",
    "tar.extractall(EXTRACTDIR) \n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(filename):\n",
    "    with open(filename) as text_file:\n",
    "        # 0: URL, 1: timestamp\n",
    "        text = text_file.readlines()[2:]\n",
    "        text = [sentence.strip() for sentence in text]\n",
    "        text = list(filter(lambda line: line != '', text))\n",
    "        return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ \n",
    "    name for name \n",
    "    in os.listdir( os.path.join(EXTRACTDIR, \"text\") ) \n",
    "    if os.path.isdir( os.path.join(EXTRACTDIR, \"text\", name) ) ]\n",
    "\n",
    "categories = sorted(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dokujo-tsushin',\n",
       " 'it-life-hack',\n",
       " 'kaden-channel',\n",
       " 'livedoor-homme',\n",
       " 'movie-enter',\n",
       " 'peachy',\n",
       " 'smax',\n",
       " 'sports-watch',\n",
       " 'topic-news']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans({\n",
    "    '\\n': '',\n",
    "    '\\t': '　',\n",
    "    '\\r': '',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 1.05 s, total: 2.92 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_text = []\n",
    "all_label = []\n",
    "\n",
    "for cat in categories:\n",
    "    files = glob.glob(os.path.join(EXTRACTDIR, \"text\", cat, \"{}*.txt\".format(cat)))\n",
    "    files = sorted(files)\n",
    "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
    "    label = [cat] * len(body)\n",
    "    \n",
    "    all_text.extend(body)\n",
    "    all_label.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : all_text, 'label' : all_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "0  dokujo-tsushin  友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...\n",
       "1  dokujo-tsushin  ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...\n",
       "2  dokujo-tsushin  相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が...\n",
       "3  dokujo-tsushin  ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...\n",
       "4  dokujo-tsushin  税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=23).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports-watch</td>\n",
       "      <td>新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaden-channel</td>\n",
       "      <td>家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peachy</td>\n",
       "      <td>彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>livedoor-homme</td>\n",
       "      <td>快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "0    sports-watch  新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...\n",
       "1   kaden-channel  家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...\n",
       "2          peachy  彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...\n",
       "3  livedoor-homme  快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...\n",
       "4  dokujo-tsushin  独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as tsv files.  \n",
    "test:dev:train = 2:2:6. To check the usability of finetuning, we also prepare sampled training data (1/5 of full training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "df[len(df)*2 // 5:].to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df)*2 // 5:].sample(frac=0.2, random_state=23).to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune pre-trained model\n",
    "\n",
    "It will take a lot of hours to execute the following cells on CPU environment.  \n",
    "You can also use colab to recieve the power of TPU. You need to uplode the created data onto your GCS bucket.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zZH2GWe0U-7GjJ2w2duodFfEUptvHjcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = '../model/model.ckpt-1400000'\n",
    "FINETUNE_OUTPUT_DIR = '../model/livedoor_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/minhpqn/workspace/bert-japanese/src/../bert\n",
      "Loaded a trained SentencePiece model.\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x18233b62f0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/livedoor_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2714c278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Writing example 0 of 4421\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 大島 優 子が ここから どう 破滅 していく のか ? ▁『 闇 金 ウシ ジ マ くん 』 特 報 解禁 “ 闇 金 ” という 禁 断 の 題材 を リアル に 描いた 漫画 史上 最大の 問題 作 「 闇 金 ウシ ジ マ くん 」 が 、 映画化 され 8 月 25 日から 公開 。 その 特 報 映像 が 遂に 解禁 となった 。 債務 者を 非 情 に追い 込み 取り 立て る 最強 の 闇 金 ウシ ジ マ には 若手 実力 派 俳優の 山田 孝 之 。 人生 の目的 を見 失 い 出会い カフェ に 出入り する フリー ター 鈴木 未 來 には akb 48 の 大島 優 子 。 過去 最大 イベント を成功させ て 人生 を 一発 逆転 し 成り 上 が ろうとする イベント サークル の代表 ・ 小川 純 には 『 荒川 アンダー ザ ブリッジ 』 の 林 遣 都 。 その他 、 崎 本 大 海 、 や べ きょう すけ が ドラマ シリーズ から 引き続き 登場 。 さらに 映画 版 新 キャスト には 、 新井 浩 文 、 岡田 義 徳 、 ム ロ ツ ヨシ 、 鈴 之助 、 内田 春 菊 、 黒 沢 あ す か など 個性的な 役者 が 揃い 、 エ グ い 世界 を より 危険 に 彩 る 。 今回 、 映画 『 闇 金 ウシ ジ マ くん 』 特 報 映像 が 解禁 となったが 、 わずか 30 秒 の 短い 映像 ながらも ス リル 満 点 に 仕 上がって いる 。 この 予告編 では 、 大島 優 子 はまだ きれい な 姿で いる が 、 本作では 母親の 借金 を 肩 代わり したことで 、 ウシ ジ マ から 取り 立て を受け 追い つ められ ていく 役 。 女の子 たちが 金 のために 時間 を切り 売り する 「 出会い カフェ 」 に 踏み 入れ て 堕 ち ていく 。 ここから どう 変わる のか 見 ものである 。 さらに 、 原作 ファン には 嬉 しい 、 肉 蝮 ( に くま む し ) の 有名な 「 あの 」 シーン を思わせる カット が チ ラ リ と 登場する の も 見逃 せない 。 映画 『 闇 金 ウシ ジ マ くん 』 は 8 月 25 日 ( 土 ) より 全国 公開 。 【 mo vi e ▁ enter お すすめ 記事 】 ・ 石川 梨 華 、 ナンバー 1 ホス テス を目指し 奮闘 ・ 美 山 加 恋 と 優 香 が 福島 に ! ▁ 絆 をつなぐ 大 切 さを 映画 を通して 伝える ・ 福田 萌 、 ジャガイモ 型 ゴースト に襲われ た 恐怖 体験 を 告白 ・ 長 澤 まさ み の 胸 元 に ハート が バク バク 、 モ テ キ 「 みゆき の部屋 & る み 子 の部屋 」 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 9 9648 2501 4367 11346 1258 28559 3263 1974 3017 138 6813 252 18816 254 157 6817 36 1757 2313 22106 1314 6813 252 809 49 3649 1514 10 12626 18 9337 17 8563 1302 3524 1877 451 332 23 6813 252 18816 254 157 6817 21 12 7 7723 79 50 22 228 532 1069 8 65 1757 2313 1337 12 16104 22106 72 8 9040 6296 696 2834 9427 1330 1034 3480 56 10041 10 6813 252 18816 254 157 42 5350 6597 591 13713 3142 2079 834 8 4221 14227 1429 2901 128 14180 7640 17 13114 35 1169 470 2636 1006 31106 42 11147 1135 10 9648 2501 129 8 2756 1032 906 19638 58 4221 18 22852 5790 32 15171 113 12 20111 906 7655 7111 13 8264 2235 42 39 10767 9607 286 8339 36 10 707 9381 873 8 3647 7 1105 96 62 300 7 26 1720 3137 7712 12 1000 340 28 4697 2498 8 476 244 349 123 5096 42 7 16424 4496 251 7 6054 335 880 7 193 232 319 14606 7 8199 4162 7 15060 772 4755 7 657 768 703 263 95 45 28999 7438 12 27746 7 234 346 128 301 18 94 3657 17 4460 56 8 11641 7 244 39 6813 252 18816 254 157 6817 36 1757 2313 1337 12 22106 4670 7 3680 141 1053 10 3729 1337 3684 60 6428 1127 313 17 2499 11144 546 8 80 30687 38 7 9648 2501 129 6389 27593 57 16416 546 12 7 11501 19119 13337 18 4026 10337 7608 7 18816 254 157 28 1034 3480 620 4362 192 14704 2199 610 8 12953 3103 252 557 364 9541 4935 35 23 14180 7640 21 17 8652 2986 58 29584 662 2199 8 11346 1258 10848 1974 310 753 8 476 7 2905 777 42 23015 3456 7 2039 0 15 17 14032 561 32 14 10 3225 23 10252 21 1652 22839 3685 12 276 114 146 20 5617 10 30 30112 13035 8 244 39 6813 252 18816 254 157 6817 36 11 50 22 228 33 15 811 14 94 676 1069 8 17536 2100 3188 255 9 27884 220 22050 2110 7305 13 4637 7681 1638 7 5046 24 13640 6295 10987 23171 13 400 84 1117 2865 20 2501 1403 12 4090 17 543 9 19856 24702 62 1899 12267 244 3343 11137 13 9692 18473 7 26399 177 21679 15082 40 7962 3587 18 10608 13 117 2984 8553 206 10 4032 156 17 4769 12 11539 11539 7 399 333 260 23 25308 16216 763 56 206 129 16216 21 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: movie-enter (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] ▁ インタビュー : クリスチャン ・ ベール 「 演じる ことができる の は 役者 だけ 」 公開 当時 、 全米 歴代 2 位 という メガ ヒット を記録し 、 世界中で 社会 現象 を 巻き 起こした 『 ダーク ナイト 』 から 4 年 、「 誰も が 衝撃 を受ける 」 と クリストファー ・ ノー ラン 監督 が 自信 を持って 贈 る 『 ダーク ナイト ▁ ライ ジング 』 が 7 月 24 日より 公開された 。 ゴ ッサ ム シティ を舞台に 前作 を超える 最後の 戦い を繰り広げる 本作 で 、『 バットマン ▁ ビ ギン ズ 』『 ダーク ナイト 』 に続き 、 ブルース ・ ウェイン / ダーク ナイト を演じる クリスチャン ・ ベール に 、 本作 に登場する キャラクター や ノー ラン 監督 について 語 って もらった 。 アン ・ ハ サ ウェイ なら 「 や れる 」 — — 本作の 脚本 について どう 思い ます か ? クリスチャン ・ ベール ( 以下 、 クリスチャン ) : 三部作 の 最後 を飾る の に ふさわしい 内容 の脚本 だ と思った よ 。 描く だけ の価値 のある 物語 だった し 、 以前は クリストファー ・ ノー ラン 監督 が 果たして 3 本 目 を作る の かどうか 定 か ではなかった けれど 、 今回の 脚本 を 読 んで 、 なぜ 彼が 3 本 目を 作 ろうとした のか 、 よく 理解 できた 気 が した んだ 。 — — 前作 で ブルース ・ ウェイン / ダーク ナイト は 、 肉体 的にも 精神的 にも 大きな 傷 を負い ました が 、 今回の ブルース は どう なって います か ? クリスチャン : 今回の 彼 も やはり 肉体 的 、 精神的 に 傷を負っ ている 状態 。 前作 で 自らが 選んだ 決断 の せい で 苦しんで いる んだ 。 ゴ ッサ ム シティ の 希望 のために 選んだ 道 として 短い 間は 問題 なかったが 、 真実 は やがて 白 日 の下 にさらされ る 。 ブルース にとっては 人生 で最も 厳しい 時 を迎える ことになる んだ 。 自 責 の 念 に押し 潰 される んだ よ 。 そして 、 バットマン は 姿を消し てしまう の さ 。 — — そんな 彼の 前に 、 新たな キャラクター が現れ て 、 事態 が変化し ていき ます よ ね 。 クリスチャン : アン ・ ハ サ ウェイ 演じる セ リーナ は不 作 法 で 、 気 が強く て 、 厚 か ましく て 、 バットマン が ブルース である ことも お 構 いな し という 女性 な んだ 。 でも ブルース は 、 彼女の そんな ところ に興味 を抱いた んだ よ 。 何 しろ 大 勢 の 人に 正体 を隠し ている だけに 、 彼 にとって 彼女は 非常に 興味 を そ そ る 、 刺激 的で 、 ユーモア のある 女性 として 映 る んだ 。 彼女は 、 再び 人々の 気 力を 蘇 らせる 人 なん だよ 。 — — キャット ウーマン を演じた アン ・ ハ サ ウェイ について どう 思い ます か ? クリスチャン : 最初の オーディション で の脚本 の 読み 合わせ の後 、 僕 は すぐに ノー ラン 監督の 方を 向 いた んだ 。 という の も 、 彼は いつも カメラ の 横 に 立っている から 、 果たして 僕 の 立っている 位置 から 見え ている ものが 、 ちゃん と 彼に も 見える かどうか わか らなかった から ね 。 僕 は 、「 彼女 なら や [SEP]\n",
      "INFO:tensorflow:input_ids: 4 9 5564 76 10817 13 10279 23 11971 1046 10 11 7438 926 21 1069 412 7 3521 3514 25 205 49 5745 2709 7381 7 20408 567 2420 18 3949 14102 39 9199 3039 36 28 37 16 93 10365 12 5960 1818 21 20 18452 13 1702 466 464 12 16545 4385 5461 56 39 9199 3039 9 1244 9135 36 12 46 22 249 2304 7859 8 425 6485 193 1776 11578 4068 3122 1240 2648 25414 3118 19 388 29093 9 365 7633 111 1507 9199 3039 36 12317 7 6547 13 15119 140 9199 3039 14560 10817 13 10279 17 7 3118 2753 911 26 1702 466 464 257 274 341 22070 8 500 13 380 209 2154 1598 23 26 2991 21 19423 19423 6322 3125 257 1258 2969 3418 95 3017 10817 13 10279 15 1181 7 10817 14 76 24100 10 6450 16671 10 17 23005 1205 17823 314 12700 842 8 14615 926 18178 863 1101 121 32 7 5949 18452 13 1702 466 464 12 26448 31 96 303 3865 10 4615 609 95 6838 24585 7 16058 3125 18 3183 2011 7 11133 3446 31 96 7589 332 20563 1974 7 1600 2985 2747 474 12 29 736 8 19423 19423 4068 19 6547 13 15119 140 9199 3039 11 7 9456 14245 14460 137 622 2169 28738 5363 12 7 16058 6547 11 1258 10019 19433 95 3017 10817 76 16058 2189 30 5770 9456 160 7 14460 17 28608 68 621 8 4068 19 12438 17421 12294 10 1501 19 30662 546 736 8 425 6485 193 1776 10 5072 557 17421 162 34 3729 9635 451 6691 7 10553 11 4248 422 33 2757 21807 56 8 6547 5784 4221 4867 5209 180 7500 2060 736 8 957 11685 10 4456 16245 11382 98 736 842 8 862 7 29093 11 26405 2201 10 338 8 19423 19423 11152 1063 1019 7 1379 911 8322 58 7 2889 26313 13749 3418 842 969 8 10817 76 500 13 380 209 2154 11971 342 9274 10053 332 151 19 7 474 6351 58 7 4565 95 27922 58 7 29093 12 6547 27 2464 220 12090 16289 32 49 577 57 736 8 153 6547 11 7 3296 11152 917 14727 24918 736 842 8 1059 9444 62 1436 10 3588 9774 22849 68 17509 7 2189 1522 5107 1627 8268 18 1010 1010 56 7 6699 7194 7 23729 863 577 34 6208 56 736 8 5107 7 762 9021 474 3985 7157 10825 63 4547 24152 8 19423 19423 19017 28841 9412 500 13 380 209 2154 257 1258 2969 3418 95 3017 10817 76 861 5344 19 17823 10 3009 4870 2099 7 4882 11 2607 1702 466 3278 12250 1669 308 736 8 49 10 30 7 1096 9328 2782 10 894 17 18417 28 7 26448 4882 10 18417 1958 28 11096 68 3031 7 2278 20 9831 30 9751 4615 5786 7661 28 969 8 4882 11 93 3930 1598 26 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: movie-enter (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] ▁ ブラック マジック デザイン 、 hy per de ck ▁s sd ▁ レコーダー に ▁ タイム コード 、 d n x hd ▁ qui ck time ▁ サポート を追加 【 ビデオ sa lon 】 ブラック マジック デザインは hy per de ck ▁ 2.5 ▁ パブリック ベータ 版 をリリースした 。 今回の ソフトウェア アップデート では 、 エン ベッド タイム コード の サポート 、 qui ck time ▁ への d n x hd ▁ 収録 、 s di ▁ カメラ による hy per de ck ▁s sd ▁ レコーダー への 収録 開始 機能 が追加され る 。 hy per de ck ▁ 2.5 ▁ パブリック ベータ 版 ( mac ▁os x / windows ▁ 対応 ) は 同社 web サイト より 無償 で ダウンロード 可能 。 今回の アップデート は black magic ▁de sign ▁s sd ▁ レコーダー の hy per de ck ▁ shu tt le ▁2 ▁ ならびに hy per de ck ▁studio ▁ の両 モデル に対応している 。 hy per de ck ▁ 2.5 ▁ ソフトウェア アップデート は 、 hy per de ck ▁ shu tt le ▁ ならびに hy per de ck studio ▁ に 、 タイム コード 機能 を追加 する 。 hd - s di ▁ ビデオ 信号 の 補助 データ スペース に エン ベッド されている タイム コード 情報 は 、 hy per de ck ▁ の 非 圧縮 / av id ▁d n x hd ▁ 圧縮 ビデオ ファイル に 書き 込まれる 。 ユーザー は 、 標準 rp -18 8 hd ▁ プロトコル に基づいて 、 入力 ビデオ ストリーム の タイム コード を 保存 することができ 、 収録 した ファイル に オリジナルの タイム コード 情報 を付けて 再生 することが可能 だ 。 hy per de ck ▁ shu tt le ▁ ならびに hy per de ck studio ▁ は 、 av id ▁d n x hd ▁ 収録 ・ 再生 に対応 しており 、 av id ▁ から 完全な 認定 を受けている 。 hy per de ck ▁ 2.5 ▁ ソフトウェア は 、 d n x hd ▁m x f ▁ フォーマット ファイル に加えて 、 d n x hd ▁ qui ck time ▁ の 収録 ・ 再生 オプション を追加 する 。 d n x hd ▁ ファイル を qui ck time ▁ フォーマット で ラ ッピング することにより 、 av id ▁ の 業界 標準 ファイル の エン コード を より 幅広い ソフトウェア と 使用した り 、 特定の ワーク フロー に対応した り できる 。 また 、 hy per de ck ▁ shu tt le ▁ への 収録 が 、 カメラ やその他の hd - s di ▁ ビデオ 機器 により 自動的に 開始 できるようになる 。 プロ 仕様の カメラ の多くは 収録 の 開始 / 停止 フラ グ を s di ▁ ビデオ 出力 に エン ベッド しているが 、 hy per de ck ▁ shu tt le ▁ は これらの コマンド を認識し 、 カメラ と 同期 して 収録 を開始 / 停止 できる 。 この 機能 によって カメラ と ディスク レコーダー で それぞれ 収録 機能を 起動 させ なくても hy per de ck ▁ shu tt le ▁ に収録 できるようになる 。 標準的な 方法で は 開始 / 停止 フラ グ を 出力 しない カメラ もある ため 、 今回の アップデート には タイム コード 収録 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 9 2523 10590 953 7 7914 4235 1372 3600 1785 5625 9 23021 17 9 1574 2025 7 221 272 282 7065 9 9495 3600 15191 9 3752 10916 17536 1593 1854 19338 7305 2523 10590 14565 7914 4235 1372 3600 9 7310 9 17425 16454 349 17502 8 16058 2360 16937 38 7 875 13163 1574 2025 10 3752 7 9495 3600 15191 9 105 221 272 282 7065 9 1867 7 81 3639 9 2782 71 7914 4235 1372 3600 1785 5625 9 23021 105 1867 1163 640 17639 56 8 7914 4235 1372 3600 9 7310 9 17425 16454 349 15 6888 15364 282 140 4943 9 1270 14 11 2155 4537 1487 94 15109 19 6901 1790 8 16058 16937 11 13295 28280 1542 17496 1785 5625 9 23021 10 7914 4235 1372 3600 9 28746 4987 1409 892 9 7867 7914 4235 1372 3600 21121 9 9536 693 16975 8 7914 4235 1372 3600 9 7310 9 2360 16937 11 7 7914 4235 1372 3600 9 28746 4987 1409 9 7867 7914 4235 1372 3600 30648 9 17 7 1574 2025 640 10916 35 8 7065 61 81 3639 9 1593 3173 10 4350 1167 3115 17 875 13163 134 1574 2025 525 11 7 7914 4235 1372 3600 9 10 696 7182 140 2973 2427 3023 272 282 7065 9 7182 1593 2806 17 2202 18717 8 3245 11 7 1884 10597 8934 50 7065 9 15593 4527 7 4616 1593 15984 10 1574 2025 18 2242 17668 7 1867 29 2806 17 11032 1574 2025 525 18640 3280 14123 314 8 7914 4235 1372 3600 9 28746 4987 1409 9 7867 7914 4235 1372 3600 30648 9 11 7 2973 2427 3023 272 282 7065 9 1867 13 3280 9590 453 7 2973 2427 9 28 6229 2740 6396 8 7914 4235 1372 3600 9 7310 9 2360 11 7 221 272 282 7065 1313 282 210 9 12285 2806 4440 7 221 272 282 7065 9 9495 3600 15191 9 10 1867 13 3280 6717 10916 35 8 221 272 282 7065 9 2806 18 9495 3600 15191 9 12285 19 114 13994 10054 7 2973 2427 9 10 3048 1884 2806 10 875 2025 18 94 6951 2360 20 8966 101 7 2919 6907 8592 10907 101 355 8 240 7 7914 4235 1372 3600 9 28746 4987 1409 9 105 1867 12 7 2782 20802 7065 61 81 3639 9 1593 2206 74 10704 1163 26586 8 449 16708 2782 4165 1867 10 1163 140 2004 3512 346 18 81 3639 9 1593 2152 17 875 13163 4662 7 7914 4235 1372 3600 9 28746 4987 1409 9 11 1432 6728 30064 7 2782 20 5987 55 1867 4147 140 2004 355 8 80 640 73 2782 20 4334 23021 19 832 1867 10268 10877 909 9770 7914 4235 1372 3600 9 28746 4987 1409 9 11305 26586 8 16487 9537 11 1163 140 2004 3512 346 18 2152 904 2782 553 97 7 16058 16937 42 1574 2025 1867 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] ▁ センター 試験 終了 ! ▁ 受験 生 ファン に 眞 鍋 か を り が 的 確 な アドバイス をしていた 【 話題 】 寒 い 週末 、 毎年 恒例 の センター 試験 が行われていた 。 受験 生 にとっては 大切な 日 。 ファン の 受験 を タレント の 眞 鍋 か を り も ツイッター で 応援 していた 。 「 明日 の センター 試験 なので 自信 の 持 てる 一言 ください 」 と 眞 鍋 に エール を求める ファン 。 彼女の 返答 は 「 助 詞 の 使い方 間違って る から 現 国 マジ で 気 をつけ な 」 だった 。 この 的 確 な アドバイス に 「 これは 良い 指摘 」 と ツ イー ト を評価する 声 が多く 登場した 。 また 、 眞 鍋 に コメント を もらった 受験 生 は ツイッター の フォ ロ ワー が 一気に 倍 になった ということ だ 。 さ て 今回の 彼女の き つい エール は 生 か された の だろうか 。 ■ 関連 記事 ・ facebook 投稿 で 原因 発覚 ? ▁ イタリアの 豪華 客船 、 船長 がい いとこ 見せた く て 事故 か ? 【 話題 】 ・ 傷 が 消え る ケース は 世界 初 ! ▁ 日産 が開発 の iphone ケース に 注目 【 売れ 筋 チェック 】 ・ 日本の 首都 は 吉野 家で 首相 は キ ティ ちゃん !? ▁アン サイ クロ ペ ディア の 日本の 項目 が お も しろ い 【 話題 】 ・ もはや 格闘 ドラマ ? ▁ 松 潤 主演の 「 ラッキー セブン 」 は 今後 が 楽しみ な 初回 16 . 3% 【 話題 】 ・ 魁 !! ▁ ビデオ 道場 ▁2012 年 1 月号 【 ビデオ sa lon 】 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 9 571 984 1448 543 9 5435 196 777 17 16522 10653 95 18 101 12 160 10594 57 21000 3880 17536 4346 7305 4906 128 11544 7 1863 21849 10 571 984 10686 8 5435 196 5784 27990 33 8 777 10 5435 18 2886 10 16522 10653 95 18 101 30 28915 19 5821 133 8 23 14787 10 571 984 5010 16545 10 1535 8467 24985 19120 21 20 16522 10653 17 6675 3485 777 8 3296 25293 11 23 1356 4719 10 24667 28823 56 28 295 115 13499 19 474 9833 57 21 121 8 80 160 10594 57 21000 17 23 881 4070 5853 21 20 319 2019 103 29443 891 1151 6075 8 240 7 16522 10653 17 5501 18 22070 5435 196 11 28915 10 2197 232 4078 12 10598 1892 344 3972 314 8 338 58 16058 3296 203 10805 6675 11 196 95 53 10 25907 8 25825 1617 2110 13 24337 5166 19 3275 13369 3017 9 4588 20773 18596 7 16384 5837 26504 26918 195 58 1350 95 3017 17536 4346 7305 13 2169 12 8091 56 2472 11 301 503 543 9 10425 9904 10 22021 2472 17 7928 17536 9170 1722 8390 7305 13 216 3277 11 7717 16757 1731 11 260 299 2278 19959 14133 1855 2409 719 3356 10 216 4080 12 220 30 9444 128 17536 4346 7305 13 12039 8355 1000 3017 9 720 7794 9796 23 25931 7911 21 11 6456 12 19116 57 5513 130 86 7064 17536 4346 7305 13 27595 4045 9 1593 8953 692 16 24 3692 17536 1593 1854 19338 7305 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-5\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 彼女の 香り は 、 柔軟 剤 の 香り 都内 で 一人 暮らし をしている サ ナ エ さん ( 28 歳 ・ 医療 関連 ) は 、 同僚 の ミノ リ さん ( 25 歳 ) が 返し てくれた タ オル に 感 激 した そう だ 。 「 貸 したとき よりも フ ワ フ ワ になって いて 、 いい 香り が した んです 。 女性 ならではの 心 遣い だ と思い ました 」 。 後日 、 サ ナ エ さん が 気 になる 香り の名前 を聞いた ところ 、 ミノ リ さん からは 意 外 が 答え が ... 。 「 それ 、 柔軟 剤 の 香り な んです 。 意 外 といい 感じ です よ ね 。 靴 下 を 履 く とき も 、 ふ わ っ といい 香り が す んです よ 。 今まで 人工 的な 香り は 苦手 だった んです けど 、 この 香り は 別 です 」 と 嬉 し そう に 話し てくれた 。 柔軟 剤 といえば 、 洗濯 物を 柔らかく 仕上げ るための もの と考え がち だが 、 この ところ 、 香り に こだわり のある 柔軟 剤 が増えている 。 「 タ オル は フロー ラル 系の 香り の 柔軟 剤 、 洋 服 は 夫 も 着 る の で ハーブ 系の 香り の 柔軟 剤 を使って います 」 と 話し てくれた の は ミナ ミ さん ( 28 歳 / 既婚 ・ 派遣 ) 。 ただし 、 最初から 香り に こ だ わ って 柔軟 剤 を選んだ の ではない という 。 「 部屋 干 し の 臭い 消し になると 聞いて ▁ 柔軟 剤 を使い 始めた んです 。 最初は 、 人気のある 海外 の メーカーの ものを 買 った んです けど 、 私 には 香り が 強 すぎて 、 柔軟 剤 酔 い を おこ し かけ ました ( 笑 ) 。 それ で 、 今 は 、 もっぱら 国内 メーカー のもの を使って います 」( ミナ ミ さん ) 夜 、 洗濯 をして 室内 に 干 したり 、 花粉 症 対策として 洗濯 物を 部屋 干 し する 人 が増えている 昨 今 、 悩み の タ ネ の 「 生 乾 き の 洗濯 物の 臭い 」 が 解決 する なら と 、 防 臭 効果 を 期待 して 柔軟 剤 を購入する 人は 多い 。 しかも 、 ア ロマ の良い 香り が したり 、 服 を ク シュ ク シュ する 加 減 で 香り が 広がった りと 、 香り の 面でも 柔軟 剤 は 進化 した の だから 、 女性 たちの 興味 が集まる の も 、 もっとも な 話 だろう 。 結果として 、 今まで は 、 女性 から する 「 良い 香り 」 といえば 、 香 水 や オー デ コロン 、 シャン プー や リン ス 、 石鹸 の 香り など が一般的 だったが 、 最近 は 、 ここに 柔軟 剤 の 香り が 加わった 。 お 悩み 解決 & 洗濯 後の 香り で 、 女性 は 幸せ になれ る のだ 。 ただし 、 香り は 、 人 によって 好み が 分かれ ること を忘れ てはいけない 。 「 以前 、 母 が 購入した 柔軟 剤 の 香り で 、 気持ち が悪く なり ました 」 と 話し てくれた の [SEP]\n",
      "INFO:tensorflow:input_ids: 4 9 3296 14975 11 7 15126 1930 10 14975 21098 19 2770 8701 3159 209 145 234 774 15 323 559 13 1946 1617 14 11 7 8154 10 19887 146 774 15 228 559 14 12 8207 13431 170 2271 17 852 4805 29 1043 314 8 23 11311 11554 632 211 592 211 592 1880 1229 7 2505 14975 12 29 13391 8 577 28212 509 20273 314 11585 5363 21 8 13489 7 209 145 234 774 12 474 367 14975 2228 12290 917 7 19887 146 774 994 1534 311 12 7124 12 2532 8 23 566 7 15126 1930 10 14975 57 13391 8 1534 311 6401 4878 2767 842 969 8 8651 184 18 13966 195 1488 30 7 1363 704 1315 6401 14975 12 263 13391 842 8 8945 5152 132 14975 11 17540 121 13391 13382 7 80 14975 11 519 2767 21 20 23015 32 1043 17 9016 13431 8 15126 1930 20711 7 24381 6550 30774 14310 14398 375 7915 15123 570 7 80 917 7 14975 17 23865 863 15126 1930 25559 8 23 170 2271 11 8592 4513 1437 14975 10 15126 1930 7 1506 1845 11 764 30 447 56 10 19 26368 1437 14975 10 15126 1930 2851 19433 21 20 9016 13431 10 11 9573 318 774 15 323 559 140 27203 13 3169 14 8 3408 7 15924 14975 17 315 314 704 341 15126 1930 14951 10 977 49 8 23 2335 6363 32 10 25923 20531 1726 23360 9 15126 1930 6943 2891 13391 8 17275 7 23981 1355 10 15135 3509 5605 201 13391 13382 7 1656 42 14975 12 1359 21858 7 15126 1930 11420 128 18 11515 32 4348 5363 15 5011 14 8 566 19 7 899 11 7 18037 1200 1646 1949 2851 19433 293 9573 318 774 14 1090 7 24381 7286 6775 17 6363 1965 7 25507 2578 16350 24381 6550 2335 6363 32 35 63 25559 12096 899 7 15710 10 170 316 10 23 196 5459 203 10 24381 8409 25923 21 12 2965 35 1598 20 7 2302 10159 1045 18 2605 55 15126 1930 21102 1445 3431 8 11383 7 88 9175 13463 14975 12 1965 7 1845 18 104 378 104 378 35 1117 1864 19 14975 12 17786 13788 7 14975 10 22570 15126 1930 11 3820 29 10 6129 7 577 3121 8268 21141 10 30 7 4621 57 417 2888 8 6895 7 8945 11 7 577 28 35 23 4070 14975 21 20711 7 1403 164 26 844 189 18952 7 3598 7972 26 558 60 7 30340 10 14975 45 12254 1100 7 9081 11 7 8286 15126 1930 10 14975 12 16250 8 220 15710 2965 763 24381 494 14975 19 7 577 11 15199 18152 56 6312 8 3408 7 14975 11 7 63 73 16419 12 8977 900 19828 25934 8 23 4412 7 865 12 16868 15126 1930 10 14975 19 7 8053 15842 1700 5363 21 20 9016 13431 10 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: dokujo-tsushin (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 4421\n",
      "INFO:tensorflow:  Batch size = 4\n",
      "INFO:tensorflow:  Num steps = 11052\n",
      "WARNING:tensorflow:From ../src/run_classifier.py:426: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (4, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (4, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (4,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (4,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (4, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (9, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (9,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-04-17 09:48:13.739826: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../model/livedoor_output/model.ckpt.\n",
      "^C\n",
      "CPU times: user 5.1 s, sys: 9.96 s, total: 15.1 s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# It will take many hours on CPU environment.\n",
    "\n",
    "!python3 ../src/run_classifier.py \\\n",
    "  --task_name=livedoor \\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=/Users/minhpqn/workspace/data/livedoor \\\n",
    "  --model_file=../model/wiki-ja.model \\\n",
    "  --vocab_file=../model/wiki-ja.vocab \\\n",
    "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
    "  --max_seq_length=512 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=10 \\\n",
    "  --output_dir={FINETUNE_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the finetuned model\n",
    "\n",
    "Let's predict test data using the finetuned model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/minhpqn/workspace/bert-japanese/src/../bert\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import tokenization_sentencepiece as tokenization\n",
    "from run_classifier import LivedoorProcessor\n",
    "from run_classifier import model_fn_builder\n",
    "from run_classifier import file_based_input_fn_builder\n",
    "from run_classifier import file_based_convert_examples_to_features\n",
    "from utils import str_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "\n",
    "import modeling\n",
    "import optimization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ckpts = glob.glob(\"{}/model.ckpt*data*\".format(FINETUNE_OUTPUT_DIR))\n",
    "latest_ckpt = sorted(output_ckpts)[-1]\n",
    "FINETUNED_MODEL_PATH = latest_ckpt.split('.data-00000-of-00001')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    '''Parameters.'''\n",
    "    def __init__(self):\n",
    "        self.model_file = \"../model/wiki-ja.model\"\n",
    "        self.vocab_file = \"../model/wiki-ja.vocab\"\n",
    "        self.do_lower_case = True\n",
    "        self.use_tpu = False\n",
    "        self.output_dir = \"/dummy\"\n",
    "        self.data_dir = \"../data/livedoor\"\n",
    "        self.max_seq_length = 512\n",
    "        self.init_checkpoint = FINETUNED_MODEL_PATH\n",
    "        self.predict_batch_size = 4\n",
    "        \n",
    "        # The following parameters are not used in predictions.\n",
    "        # Just use to create RunConfig.\n",
    "        self.master = None\n",
    "        self.save_checkpoints_steps = 1\n",
    "        self.iterations_per_loop = 1\n",
    "        self.num_tpu_cores = 1\n",
    "        self.learning_rate = 0\n",
    "        self.num_warmup_steps = 0\n",
    "        self.num_train_steps = 0\n",
    "        self.train_batch_size = 0\n",
    "        self.eval_batch_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LivedoorProcessor()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=FLAGS.model_file, vocab_file=FLAGS.vocab_file,\n",
    "    do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "        num_shards=FLAGS.num_tpu_cores,\n",
    "        per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=FLAGS.init_checkpoint,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    num_train_steps=FLAGS.num_train_steps,\n",
    "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
    "\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,\n",
    "    eval_batch_size=FLAGS.eval_batch_size,\n",
    "    predict_batch_size=FLAGS.predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_examples = processor.get_test_examples(FLAGS.data_dir)\n",
    "predict_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.tf_record')\n",
    "\n",
    "file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                        FLAGS.max_seq_length, tokenizer,\n",
    "                                        predict_file.name)\n",
    "\n",
    "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file.name,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=predict_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# It will take a few hours on CPU environment.\n",
    "\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test data set and add prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = [ label_list[elem['probabilities'].argmax()] for elem in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A littel more detailed check using `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/livedoor/train.tsv\", sep='\\t')\n",
    "dev_df = pd.read_csv(\"../data/livedoor/dev.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -q -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_df = pd.concat([train_df, dev_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
    "train_dev_ys = train_dev_df['label']\n",
    "\n",
    "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
    "test_ys = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=750)\n",
    "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
    "test_xs_ = vectorizer.transform(test_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
    "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200,\n",
    "                                   validation_fraction=len(train_df)/len(dev_df),\n",
    "                                   n_iter_no_change=5,\n",
    "                                   tol=0.01,\n",
    "                                   random_state=23)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# model = GradientBoostingClassifier(n_estimators=200,\n",
    "#                                    validation_fraction=len(dev_df)/len(train_df),\n",
    "#                                    n_iter_no_change=5,\n",
    "#                                    tol=0.01,\n",
    "#                                    random_state=23)\n",
    "\n",
    "model.fit(train_dev_xs_, train_dev_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
